 "Accuracy" refers to how close a measurement is to the true value;
 "Precision" has to do with how much information you have about a quantity, how uniquely you have it pinned down.

 Integers have complete accuracy, 2 is exactly 2. But integers lack accuracy, dividing both 5 and 4 over 2 will both get 2.
 Floating point numbers are accurate but have poor accuracy. 0.333333 can ever be equal to 1/3; we can never have enough 3's.